{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ONN_Usage_Example.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ugTEiBmBV3Cc","colab_type":"text"},"source":["#Installing Dependencies"]},{"cell_type":"code","metadata":{"id":"FbEX3YFwKCxy","colab_type":"code","colab":{}},"source":["!pip install --upgrade onn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CCBv8CqCe5Ao","colab_type":"code","colab":{}},"source":["!pip install -U imbalanced-learn"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XbYfcIpkV-SA","colab_type":"text"},"source":["##Importing Dependencies"]},{"cell_type":"code","metadata":{"id":"9xT-ZdVsKH6z","colab_type":"code","colab":{}},"source":["from onn.OnlineNeuralNetwork import ONN\n","from onn.OnlineNeuralNetwork import ONN_THS\n","from sklearn.datasets import make_classification, make_circles\n","from sklearn.model_selection import train_test_split\n","import torch\n","from sklearn.metrics import accuracy_score, balanced_accuracy_score\n","from imblearn.datasets import make_imbalance\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N9H22wxBWB9f","colab_type":"text"},"source":["## Initializing Network"]},{"cell_type":"code","metadata":{"id":"1wOHgHL1LieT","colab_type":"code","colab":{}},"source":["onn_network = ONN(features_size=10, max_num_hidden_layers=5, qtd_neuron_per_hidden_layer=40, n_classes=10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eYqkIyxyWI2h","colab_type":"text"},"source":["##Creating Fake Classification Dataset"]},{"cell_type":"code","metadata":{"id":"WXgNSF9gL69F","colab_type":"code","colab":{}},"source":["X, Y = make_classification(n_samples=50000, n_features=10, n_informative=4, n_redundant=0, n_classes=10,\n","                           n_clusters_per_class=1, class_sep=3)\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"THGPFSWJWPEm","colab_type":"text"},"source":["##Learning and predicting at the same time"]},{"cell_type":"code","metadata":{"id":"70J3ZYtmL-Zm","colab_type":"code","outputId":"b5934e61-4009-4d94-c948-b79205a4ac64","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1576102468120,"user_tz":180,"elapsed":211056,"user":{"displayName":"Alison Carrera","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBiC3bAM0x7xHWmPbnaEJt00KpgQ16GzN0SoC6X=s64","userId":"05273478487081887480"}}},"source":["for i in range(len(X_train)):\n","  onn_network.partial_fit(np.asarray([X_train[i, :]]), np.asarray([y_train[i]]))\n","  \n","  if i % 1000 == 0:\n","    predictions = onn_network.predict(X_test)\n","    print(\"Online Accuracy: {}\".format(balanced_accuracy_score(y_test, predictions)))"],"execution_count":85,"outputs":[{"output_type":"stream","text":["Online Accuracy: 0.11155993574278973\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.83945197 0.04013699 0.04013699 0.04013699 0.04013699]\n","Training Loss: 1.1259372\n","Online Accuracy: 0.9660054323032371\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.83991873 0.04002029 0.04002029 0.04002029 0.04002029]\n","Training Loss: 0.2084848\n","Online Accuracy: 0.9678860869986063\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8399446  0.04002719 0.04000937 0.04000937 0.04000937]\n","Training Loss: 0.17356381\n","Online Accuracy: 0.9749912036154884\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.83994657 0.04001333 0.04001333 0.04001333 0.04001333]\n","Training Loss: 0.14811444\n","Online Accuracy: 0.9760470086129949\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8399631  0.04000921 0.04000921 0.04000921 0.04000921]\n","Training Loss: 0.15638338\n","Online Accuracy: 0.9759461010627343\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8399948  0.04000129 0.04000129 0.04000129 0.04000129]\n","Training Loss: 0.15918425\n","Online Accuracy: 0.9762298100262223\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.83685434 0.04211017 0.04103326 0.04000113 0.04000113]\n","Training Loss: 0.12820534\n","Online Accuracy: 0.9734934993336708\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.83354604 0.04303478 0.04209974 0.04084937 0.04047008]\n","Training Loss: 0.12739542\n","Online Accuracy: 0.9765858212368291\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.836608   0.04189508 0.04080003 0.04044948 0.04024739]\n","Training Loss: 0.15056889\n","Online Accuracy: 0.9694995985295123\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8214332  0.04448996 0.04486483 0.04485038 0.04436166]\n","Training Loss: 0.1568306\n","Online Accuracy: 0.9722161084435935\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8268172  0.0438682  0.04373552 0.0432617  0.04231739]\n","Training Loss: 0.10041856\n","Online Accuracy: 0.9793201142553297\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8301994  0.04509752 0.04322343 0.04146545 0.04001413]\n","Training Loss: 0.12613085\n","Online Accuracy: 0.9771750367234034\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8232066  0.04702337 0.04448063 0.04378786 0.04150158]\n","Training Loss: 0.16321456\n","Online Accuracy: 0.9750682231662537\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.82689005 0.0445901  0.04437115 0.04317188 0.04097684]\n","Training Loss: 0.10495493\n","Online Accuracy: 0.9787383647721907\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.82549715 0.04367852 0.04392754 0.04462231 0.04227444]\n","Training Loss: 0.10634167\n","Online Accuracy: 0.9794467089058733\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.81549215 0.04575287 0.04738164 0.04483144 0.04654191]\n","Training Loss: 0.14667726\n","Online Accuracy: 0.9769883296207222\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.82577324 0.04452407 0.04485111 0.04321511 0.04163649]\n","Training Loss: 0.14000477\n","Online Accuracy: 0.9786510052546081\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8261077  0.04569656 0.04352124 0.04264664 0.04202785]\n","Training Loss: 0.15772316\n","Online Accuracy: 0.9776669770134108\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8190345  0.04555438 0.04642465 0.04463224 0.04435421]\n","Training Loss: 0.16543648\n","Online Accuracy: 0.9747771215793634\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.82290256 0.04383572 0.04445791 0.04463074 0.04417313]\n","Training Loss: 0.12946145\n","Online Accuracy: 0.9771098788422348\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8160727  0.04580708 0.04586349 0.04641246 0.04584425]\n","Training Loss: 0.14564559\n","Online Accuracy: 0.9775065630329303\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8137833  0.04646996 0.0465363  0.04649591 0.04671448]\n","Training Loss: 0.16968141\n","Online Accuracy: 0.9809745269522114\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8296316  0.04269851 0.04328017 0.04234044 0.04204924]\n","Training Loss: 0.12620583\n","Online Accuracy: 0.9772430647845771\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.83076835 0.04193426 0.04274474 0.04261354 0.04193913]\n","Training Loss: 0.10832662\n","Online Accuracy: 0.9796010077059348\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8204304  0.04591222 0.04622623 0.04318798 0.04424318]\n","Training Loss: 0.14431201\n","Online Accuracy: 0.9812657937342866\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8143497  0.04637644 0.0462814  0.04654269 0.04644987]\n","Training Loss: 0.15945143\n","Online Accuracy: 0.9769139668701705\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.81192374 0.04839997 0.04719576 0.04550314 0.04697742]\n","Training Loss: 0.2016251\n","Online Accuracy: 0.9749750747316586\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.80260354 0.04931231 0.04918544 0.04939459 0.04950411]\n","Training Loss: 0.16540474\n","Online Accuracy: 0.9797937233542597\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8201305  0.04568565 0.04690736 0.04353945 0.04373699]\n","Training Loss: 0.16044155\n","Online Accuracy: 0.9809372878387903\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8204212  0.04450759 0.04472222 0.04487672 0.04547223]\n","Training Loss: 0.19771938\n","Online Accuracy: 0.9791606454827134\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.820112   0.04510773 0.04483014 0.0448883  0.04506194]\n","Training Loss: 0.10962035\n","Online Accuracy: 0.9801457643623527\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8130196  0.04664997 0.0468505  0.04638076 0.04709918]\n","Training Loss: 0.11915081\n","Online Accuracy: 0.9807909884090209\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.82530814 0.04320473 0.04334794 0.04411471 0.04402446]\n","Training Loss: 0.15877527\n","Online Accuracy: 0.9819908183923609\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.820904   0.04438306 0.04534585 0.04500311 0.04436396]\n","Training Loss: 0.10952481\n","Online Accuracy: 0.9803995616807706\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.82685304 0.04266918 0.04349273 0.04341133 0.04357371]\n","Training Loss: 0.13681331\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_K01fvy7Tj7Z","colab_type":"text"},"source":["# Learning in batch with CUDA"]},{"cell_type":"code","metadata":{"id":"Jg1UJWvDTjJc","colab_type":"code","outputId":"6d85e55f-083f-4131-fe49-4f4022a7f543","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1576102473952,"user_tz":180,"elapsed":214654,"user":{"displayName":"Alison Carrera","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBiC3bAM0x7xHWmPbnaEJt00KpgQ16GzN0SoC6X=s64","userId":"05273478487081887480"}}},"source":["onn_network = ONN(features_size=10, max_num_hidden_layers=5, qtd_neuron_per_hidden_layer=40, n_classes=10, batch_size=10, use_cuda=True)"],"execution_count":86,"outputs":[{"output_type":"stream","text":["Using CUDA :]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Uoxk5Jk_UYKJ","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset, DataLoader\n","class Dataset(Dataset):\n","\n","  def __init__(self, X, Y):\n","    self.X = X\n","    self.Y = Y\n","\n","  def __len__(self):\n","      return len(self.X)\n","\n","  def __getitem__(self, idx):\n","      X = self.X[idx],\n","      Y = self.Y[idx]\n","\n","      return X, Y\n","    \n","transformed_dataset = Dataset(X_train, y_train)\n","dataloader = DataLoader(transformed_dataset, batch_size=10,shuffle=True, num_workers=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8jz4S-SVUAMx","colab_type":"code","outputId":"b758db69-5ae6-435c-f6b0-1ef3d2d0c8aa","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1576102517485,"user_tz":180,"elapsed":257029,"user":{"displayName":"Alison Carrera","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBiC3bAM0x7xHWmPbnaEJt00KpgQ16GzN0SoC6X=s64","userId":"05273478487081887480"}}},"source":["for local_X, local_y in dataloader: \n","  onn_network.partial_fit(np.squeeze(torch.stack(local_X).numpy()), local_y.numpy())"],"execution_count":88,"outputs":[{"output_type":"stream","text":["WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8398104 0.0400474 0.0400474 0.0400474 0.0400474]\n","Training Loss: 1.0440425\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8398949  0.04002627 0.04002627 0.04002627 0.04002627]\n","Training Loss: 0.22426741\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.8399058  0.04002354 0.04002354 0.04002354 0.04002354]\n","Training Loss: 0.17775288\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u7XwSO6zVpsz","colab_type":"code","outputId":"3de4a950-964d-4815-ba5f-aeb7594f6efa","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1576102517487,"user_tz":180,"elapsed":254869,"user":{"displayName":"Alison Carrera","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBiC3bAM0x7xHWmPbnaEJt00KpgQ16GzN0SoC6X=s64","userId":"05273478487081887480"}}},"source":["predictions = onn_network.predict(X_test)\n","print(\"Accuracy: {}\".format(balanced_accuracy_score(y_test, predictions)))"],"execution_count":89,"outputs":[{"output_type":"stream","text":["Accuracy: 0.9768585011445001\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DSk4Fl4GV9NG","colab_type":"text"},"source":["#Using contextual bandit - ONN_THS"]},{"cell_type":"markdown","metadata":{"id":"vBweUP_CZaFz","colab_type":"text"},"source":["In this example the ONN acts like a contextual bandits a reinforcement learning algorithm type. "]},{"cell_type":"code","metadata":{"id":"TeFBn4erUDY3","colab_type":"code","colab":{}},"source":["X_linear, Y_linear = make_classification(n_samples=10000, n_features=2, n_informative=2, n_redundant=0, n_classes=2, n_clusters_per_class=1, class_sep=200, shuffle=True)\n","X_non_linear, Y_non_linear = make_circles(n_samples=10000, noise=0.1, factor=0.3, shuffle=True)\n","X_linear_2, Y_linear_2 = make_classification(n_samples=10000, n_features=2, n_informative=2, n_redundant=0, n_classes=2, n_clusters_per_class=1, class_sep=200, shuffle=True)\n","\n","X_linear_train = X_linear[:5000]\n","Y_linear_train = Y_linear[:5000]\n","\n","X_linear_test = X_linear[5000:]\n","Y_linear_test = Y_linear[5000:]\n","\n","X_non_linear_train = X_non_linear[:5000]\n","Y_non_linear_train = Y_non_linear[:5000]\n","\n","X_non_linear_test = X_non_linear[5000:]\n","Y_non_linear_test = Y_non_linear[5000:]\n","\n","X_linear_train_2 = X_linear_2[:5000]\n","Y_linear_train_2 = Y_linear_2[:5000]\n","\n","X_linear_test_2 = X_linear_2[5000:]\n","Y_linear_test_2 = Y_linear_2[5000:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lfnN1xG7WtF7","colab_type":"code","colab":{}},"source":["gp = ONN_THS(2, 5, 100, 2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7EmKF-y8Wytt","colab_type":"code","outputId":"6c1edbcc-b14a-449e-dff1-8789a8e33cc9","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1576102696278,"user_tz":180,"elapsed":424094,"user":{"displayName":"Alison Carrera","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBiC3bAM0x7xHWmPbnaEJt00KpgQ16GzN0SoC6X=s64","userId":"05273478487081887480"}}},"source":["for epoch in range(5):\n","\n","    for i in range(len(X_linear_train)):\n","        x = np.asarray([X_linear_train[i, :]])\n","        y = np.asarray([Y_linear_train[i]])\n","\n","        arm, exp = gp.predict(x)\n","        \n","        if arm == y[0]:  \n","          gp.partial_fit(x, y, exp)\n","          \n","        if i % 2000 == 1999:\n","          pred = []\n","          print(\"======================================================\")\n","          for i in range(len(X_linear_test)):  \n","            pred.append(gp.predict(np.asarray([X_linear_test[i, :]]))[0])\n","          print(\"Accuracy: \" + str(balanced_accuracy_score(Y_linear_test, pred)))\n","          print(\"======================================================\")\n","\n","print('Finished Training')"],"execution_count":92,"outputs":[{"output_type":"stream","text":["WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.06387616 0.06387616 0.21570592 0.32868177 0.32786   ]\n","Training Loss: 0.06777429\n","======================================================\n","Accuracy: 0.9321726290294914\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.06500413 0.04895455 0.0770593  0.3770126  0.43196943]\n","Training Loss: 0.115104966\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.06504314 0.04898417 0.0771006  0.37719348 0.43167865]\n","Training Loss: 0.0\n","======================================================\n","Accuracy: 0.8576111974479568\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.06505971 0.04899694 0.07711567 0.3772635  0.43156415]\n","Training Loss: 0.0\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.07264031 0.04030425 0.07005572 0.36207    0.4549297 ]\n","Training Loss: 0.039341945\n","======================================================\n","Accuracy: 0.8541583992380737\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.05263599 0.04004289 0.04004225 0.27240914 0.59486973]\n","Training Loss: 0.122868255\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.07259597 0.04001465 0.04001465 0.1942651  0.6531096 ]\n","Training Loss: 1.4758105e-07\n","======================================================\n","Accuracy: 0.8597973189209118\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.08295249 0.04000717 0.0400067  0.14902891 0.68800473]\n","Training Loss: 0.0\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.08867676 0.04000434 0.04000427 0.12289678 0.70841783]\n","Training Loss: 0.0\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.0927284  0.0400029  0.04000284 0.1039959  0.72326994]\n","Training Loss: 0.0\n","======================================================\n","Accuracy: 0.8909918738110905\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.09557841 0.04000211 0.04000211 0.09053744 0.73388   ]\n","Training Loss: 0.0\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.09780576 0.04000159 0.04000154 0.07994655 0.74224454]\n","Training Loss: 0.0\n","======================================================\n","Accuracy: 0.8877800578101278\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.09949406 0.04000128 0.0400011  0.07189556 0.74860793]\n","Training Loss: 0.0\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.10088598 0.04000102 0.04000102 0.06524085 0.75387114]\n","Training Loss: 0.0\n","======================================================\n","Accuracy: 0.8586864965475218\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04325856 0.04000146 0.04000146 0.07146575 0.80527276]\n","Training Loss: 0.060458094\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04395592 0.04000115 0.04000115 0.06549966 0.8105421 ]\n","Training Loss: 1.3974723e-05\n","======================================================\n","Accuracy: 0.8819023961248269\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04066825 0.04000111 0.04000111 0.06216487 0.81716466]\n","Training Loss: 0.011783526\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04116808 0.0400009  0.0400009  0.05765029 0.82117987]\n","Training Loss: 2.911041e-05\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04159164 0.04000074 0.04000074 0.05369091 0.824716  ]\n","Training Loss: 2.3050387e-05\n","======================================================\n","Accuracy: 0.8915938492891504\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04194356 0.04000063 0.04000065 0.05032303 0.82773215]\n","Training Loss: 1.807192e-05\n","======================================================\n","Accuracy: 0.8955634951317113\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04225482 0.04000055 0.04000055 0.04728437 0.8304597 ]\n","Training Loss: 1.5316018e-05\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G6myrkQjW1kj","colab_type":"code","outputId":"4dfce7b6-fbe5-46f0-fd76-bb6c9aab9ddf","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1576102866031,"user_tz":180,"elapsed":592604,"user":{"displayName":"Alison Carrera","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBiC3bAM0x7xHWmPbnaEJt00KpgQ16GzN0SoC6X=s64","userId":"05273478487081887480"}}},"source":["for epoch in range(5):\n","\n","    for i in range(len(X_non_linear_train)):\n","        x = np.asarray([X_non_linear_train[i, :]])\n","        y = np.asarray([Y_non_linear_train[i]])\n","\n","        arm, exp = gp.predict(x)\n","        \n","        if arm == y[0]:  \n","          gp.partial_fit(x, y, exp)\n","          \n","        if i % 2000 == 1999:\n","          pred = []\n","          print(\"======================================================\")\n","          for i in range(len(X_linear_test)):  \n","            pred.append(gp.predict(np.asarray([X_non_linear_test[i, :]]))[0])\n","          print(\"Accuracy: \" + str(balanced_accuracy_score(Y_non_linear_test, pred)))\n","          print(\"======================================================\")\n","\n","print('Finished Training')"],"execution_count":93,"outputs":[{"output_type":"stream","text":["WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04125949 0.04869201 0.04964674 0.05104332 0.8093584 ]\n","Training Loss: 0.047269467\n","======================================================\n","Accuracy: 0.501873123254728\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04109182 0.04131771 0.0470376  0.0547357  0.8158172 ]\n","Training Loss: 0.2581089\n","======================================================\n","Accuracy: 0.5027207953741917\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.0407271  0.04077765 0.04092487 0.05368971 0.8238807 ]\n","Training Loss: 0.25839192\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04012787 0.04012787 0.04012787 0.04012787 0.8394885 ]\n","Training Loss: 0.23019107\n","======================================================\n","Accuracy: 0.8586811310427456\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04000054 0.04000054 0.04000054 0.04000054 0.8399978 ]\n","Training Loss: 0.058671184\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04000502 0.04000502 0.04000502 0.04000502 0.83997995]\n","Training Loss: 0.021879492\n","======================================================\n","Accuracy: 0.9093607175452441\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04000001 0.04000001 0.04000001 0.04000001 0.84      ]\n","Training Loss: 0.0035963086\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04000002 0.04000002 0.04000002 0.04000002 0.8399999 ]\n","Training Loss: 0.0016941663\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04       0.04       0.04       0.04       0.84000003]\n","Training Loss: 0.0010898949\n","======================================================\n","Accuracy: 0.927711338106872\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04000005 0.04000005 0.04000005 0.04000005 0.8399998 ]\n","Training Loss: 0.0011576726\n","======================================================\n","Accuracy: 0.9281587873181847\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04000002 0.04000002 0.04000002 0.04000002 0.84      ]\n","Training Loss: 0.0012452629\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04000002 0.04000002 0.04000002 0.04000002 0.8399999 ]\n","Training Loss: 0.00055373035\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04 0.04 0.04 0.04 0.84]\n","Training Loss: 0.0003809722\n","======================================================\n","Accuracy: 0.9256629972629555\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04000005 0.04000005 0.04000005 0.04000005 0.83999974]\n","Training Loss: 0.0014935844\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04000001 0.04000001 0.04000001 0.04000001 0.84      ]\n","Training Loss: 0.0008097456\n","======================================================\n","Accuracy: 0.9332418583854464\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04       0.04       0.04       0.04       0.84000003]\n","Training Loss: 0.00022195431\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04       0.04       0.04       0.04       0.84000003]\n","Training Loss: 0.0001480652\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04       0.04       0.04       0.04       0.84000003]\n","Training Loss: 0.000110203\n","======================================================\n","Accuracy: 0.9502336421293204\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04       0.04       0.04       0.04       0.84000003]\n","Training Loss: 0.000709672\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04       0.04       0.04       0.04       0.84000003]\n","Training Loss: 0.00063480396\n","======================================================\n","Accuracy: 0.9451127900195293\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04       0.04       0.04       0.04       0.84000003]\n","Training Loss: 5.389038e-05\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"G27Vh6mI6LTi","colab_type":"text"},"source":["# Imbalanced Dataset"]},{"cell_type":"code","metadata":{"id":"E-IHNagYXgap","colab_type":"code","colab":{}},"source":["X, Y = make_classification(n_samples=10000, n_features=10, n_informative=4, n_redundant=0, n_classes=5, n_clusters_per_class=1, class_sep=200, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O5Mh3jR-6TWR","colab_type":"code","colab":{}},"source":["X_t, Y_t = make_imbalance(X, Y, sampling_strategy={0: 800, 1: 200, 2: 900, 3: 500, 4: 1500})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ryU12keU6WOp","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n","\n","X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(X_t, Y_t, test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Si9uRxRu7Ecw","colab_type":"code","colab":{}},"source":["gp = ONN_THS(10, 5, 100, 5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a21-OBBC6YrK","colab_type":"code","outputId":"e724790e-9516-4cec-dc78-e64b204e3dcd","colab":{"base_uri":"https://localhost:8080/","height":595},"executionInfo":{"status":"ok","timestamp":1576102919167,"user_tz":180,"elapsed":642860,"user":{"displayName":"Alison Carrera","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBiC3bAM0x7xHWmPbnaEJt00KpgQ16GzN0SoC6X=s64","userId":"05273478487081887480"}}},"source":["for i in range(len(X_train)):\n","    x = np.asarray([X_train[i, :]])\n","    y = np.asarray([y_train[i]])\n","\n","    arm, exp = gp.predict(x)\n","\n","    if arm == y[0]:  \n","      gp.partial_fit(x, y, exp)\n","\n","    if i % 2000 == 1999:\n","      pred = []\n","      print(\"======================================================\")\n","      for i in range(len(X_test)):  \n","        pred.append(gp.predict(np.asarray([X_test[i, :]]))[0])\n","      print(\"Accuracy: \" + str(balanced_accuracy_score(y_test, pred)))\n","      print(\"======================================================\")\n","\n","print('Finished Training')"],"execution_count":98,"outputs":[{"output_type":"stream","text":["WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04240164 0.0581313  0.20170258 0.37169677 0.32606778]\n","Training Loss: 0.08427304\n","======================================================\n","Accuracy: 0.9076715772838966\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04248263 0.05824144 0.20207655 0.37203687 0.32516247]\n","Training Loss: 2.8180893e-06\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04252382 0.05829746 0.2022661  0.37219757 0.32471508]\n","Training Loss: 1.3697098e-06\n","======================================================\n","Accuracy: 0.8584136681505685\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.06496805 0.04386451 0.11642571 0.40504125 0.3697005 ]\n","Training Loss: 0.05130389\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.06506918 0.04392262 0.11655696 0.40536597 0.36908525]\n","Training Loss: 7.2467276e-07\n","======================================================\n","Accuracy: 0.9000894639054267\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.06512065 0.04395276 0.11662393 0.40553224 0.36877042]\n","Training Loss: 4.31895e-07\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.06515684 0.04397394 0.1166664  0.40564492 0.36855793]\n","Training Loss: 3.182887e-07\n","======================================================\n","Accuracy: 0.9153477176399474\n","======================================================\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eqBRyZxh-6_h","colab_type":"code","colab":{}},"source":["gp = ONN_THS(10, 5, 100, 5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFFz2xWN6o_4","colab_type":"code","outputId":"b1c2613b-000f-4e9c-cb87-315a16b774ca","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1576102938858,"user_tz":180,"elapsed":661684,"user":{"displayName":"Alison Carrera","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBiC3bAM0x7xHWmPbnaEJt00KpgQ16GzN0SoC6X=s64","userId":"05273478487081887480"}}},"source":["for i in range(len(X_train_t)):\n","    x = np.asarray([X_train_t[i, :]])\n","    y = np.asarray([y_train_t[i]])\n","\n","    arm, exp = gp.predict(x)\n","\n","    if arm == y[0]:  \n","      gp.partial_fit(x, y, exp)\n","\n","    if i % 2000 == 1999:\n","      pred = []\n","      print(\"======================================================\")\n","      for i in range(len(X_test_t)):  \n","        pred.append(gp.predict(np.asarray([X_test_t[i, :]]))[0])\n","      print(\"Accuracy: \" + str(balanced_accuracy_score(y_test_t, pred)))\n","      print(\"======================================================\")\n","\n","print('Finished Training')"],"execution_count":100,"outputs":[{"output_type":"stream","text":["WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04830293 0.07267473 0.21758947 0.3690484  0.29238445]\n","Training Loss: 0.100844555\n","======================================================\n","Accuracy: 0.8903208022078465\n","======================================================\n","WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n","Alpha:[0.04840219 0.07281803 0.21795925 0.3694929  0.2913276 ]\n","Training Loss: 1.6427038e-07\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X3IBIV0WAqKI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}